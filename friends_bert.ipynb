{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friends_bert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM49FI1inRBMGKD7YypBM6p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b89cdddd951c4643b1fa7befc548dae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12c024de676f465c9a08b92a8a919131",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0121ce3384b34a55802d3ec015a2bd60",
              "IPY_MODEL_1d46bac2bbe74332b551ae9a68ae1aee"
            ]
          }
        },
        "12c024de676f465c9a08b92a8a919131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0121ce3384b34a55802d3ec015a2bd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dace1e49939499daa9b84839208e13d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa9832c2a60d43589b65a0376100e81d"
          }
        },
        "1d46bac2bbe74332b551ae9a68ae1aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b393f51b4aa408faf7293493b2f186d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.85kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14c02574bbba46dea2e95c90bdc38545"
          }
        },
        "9dace1e49939499daa9b84839208e13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa9832c2a60d43589b65a0376100e81d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b393f51b4aa408faf7293493b2f186d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14c02574bbba46dea2e95c90bdc38545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d195042ad2fc4680ae8fdfe28624ad2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed1ed81c84cd492da34f3349274a9c2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7fccfdd125b4fd280d323b273820689",
              "IPY_MODEL_331f34d33d52470892418259b0cea39b"
            ]
          }
        },
        "ed1ed81c84cd492da34f3349274a9c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7fccfdd125b4fd280d323b273820689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13ce080080bf4c2abb72e35cbd2ea94e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_475aa59b63134c8a84395c99a9539cc6"
          }
        },
        "331f34d33d52470892418259b0cea39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46c13717b43c46ed985048b6ca7766fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 168kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cf1be8ee071401faa5b81d40142d674"
          }
        },
        "13ce080080bf4c2abb72e35cbd2ea94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "475aa59b63134c8a84395c99a9539cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46c13717b43c46ed985048b6ca7766fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cf1be8ee071401faa5b81d40142d674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0385859d00694bcbaa480affd323667e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c771653058484dca968f8b1b3051d4b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31616f1202084d1499babe185032de0d",
              "IPY_MODEL_5d86c6d7f77e4253943e2b73f6adad93"
            ]
          }
        },
        "c771653058484dca968f8b1b3051d4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31616f1202084d1499babe185032de0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd59156f663341bda89cddbeccc388e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b765a7d634a46a5a0b4fae443430916"
          }
        },
        "5d86c6d7f77e4253943e2b73f6adad93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2bb6f46e74d34436ae53fef7437833c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 972kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d73a35fae2d648feb5267d8001e59afa"
          }
        },
        "dd59156f663341bda89cddbeccc388e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b765a7d634a46a5a0b4fae443430916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bb6f46e74d34436ae53fef7437833c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d73a35fae2d648feb5267d8001e59afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungyeonchu/jungyeon_nlp/blob/main/friends_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1CUi9QwiEc3"
      },
      "source": [
        "**필요 package 모두 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ziw_hgHSiE8k",
        "outputId": "af7bf91b-d89d-44b2-8462-783f19789a01"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0q9eT2foPyt",
        "outputId": "2874f797-841f-444f-bbf7-47f0a3fdd5af"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 22.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 27.3MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 21.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 16.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 19.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 16.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 14.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 13.4MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 13.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c2c72869b8d493557f6be49149c5eb229efec1ff7eff6fd4d9d57104b7927f75\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vabMzD9yjDy9"
      },
      "source": [
        "import json\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tag import pos_tag\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk import Text\r\n",
        "import collections\r\n",
        "from keras.layers.core import Dense, SpatialDropout1D \r\n",
        "from keras.layers.convolutional import Conv1D \r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.preprocessing.sequence import pad_sequences \r\n",
        "from keras.utils import np_utils \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import torch\r\n",
        "from transformers import BertTokenizer\r\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import time\r\n",
        "import datetime\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng9pj5aTrZVb"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxGTxwIQiM4h"
      },
      "source": [
        "**데이터 정제**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obQA2BR5iG0D",
        "outputId": "a86129eb-70b4-4f19-d2a2-bc5d545fa974"
      },
      "source": [
        "nltk.download('stopwords')\r\n",
        "stops = set(stopwords.words('english'))\r\n",
        "stemmer = nltk.stem.SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGAZSFjMnYo-",
        "outputId": "2c235686-0d5f-4b1e-e692-9c2d069af1db"
      },
      "source": [
        "%cd /content/gdrive/MyDrive\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg2VQbf3NRHR"
      },
      "source": [
        "#파일 불러오기\r\n",
        "with open('./friends_train.json') as json_file:\r\n",
        "    json_train = json.load(json_file)\r\n",
        "with open('./friends_test.json') as json_file:\r\n",
        "    json_test = json.load(json_file)\r\n",
        "with open('./friends_dev.json') as json_file:\r\n",
        "    json_dev = json.load(json_file)\r\n",
        "#데이터 정제 함수\r\n",
        "def cleaning(str):\r\n",
        "    replaceAll = str\r\n",
        "    only_english = re.sub('[^a-zA-Z]', ' ', replaceAll)\r\n",
        "    no_capitals = only_english.lower().split()\r\n",
        "    no_stops = [word for word in no_capitals if not word in stops]\r\n",
        "    stemmer_words = [stemmer.stem(word) for word in no_stops]\r\n",
        "    return ' '.join(stemmer_words)\r\n",
        "\r\n",
        "i = 0\r\n",
        "train_data=[]\r\n",
        "for rows in json_train:\r\n",
        "    for row in rows:\r\n",
        "        train_data.append([cleaning(row['utterance']), row['emotion']])\r\n",
        "for rows in json_test:\r\n",
        "    for row in rows:\r\n",
        "        train_data.append([cleaning(row['utterance']), row['emotion']])\r\n",
        "for rows in json_dev:\r\n",
        "    for row in rows:\r\n",
        "        train_data.append([cleaning(row['utterance']), row['emotion']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-_tYp0ppKqO"
      },
      "source": [
        "test_data = []\r\n",
        "for rows in json_test:\r\n",
        "    for row in rows:\r\n",
        "        test_data.append([cleaning(row['utterance']), row['emotion']])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GzS09QxjpwE"
      },
      "source": [
        "**데이터 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "b89cdddd951c4643b1fa7befc548dae0",
            "12c024de676f465c9a08b92a8a919131",
            "0121ce3384b34a55802d3ec015a2bd60",
            "1d46bac2bbe74332b551ae9a68ae1aee",
            "9dace1e49939499daa9b84839208e13d",
            "fa9832c2a60d43589b65a0376100e81d",
            "0b393f51b4aa408faf7293493b2f186d",
            "14c02574bbba46dea2e95c90bdc38545",
            "d195042ad2fc4680ae8fdfe28624ad2b",
            "ed1ed81c84cd492da34f3349274a9c2d",
            "b7fccfdd125b4fd280d323b273820689",
            "331f34d33d52470892418259b0cea39b",
            "13ce080080bf4c2abb72e35cbd2ea94e",
            "475aa59b63134c8a84395c99a9539cc6",
            "46c13717b43c46ed985048b6ca7766fb",
            "0cf1be8ee071401faa5b81d40142d674",
            "0385859d00694bcbaa480affd323667e",
            "c771653058484dca968f8b1b3051d4b6",
            "31616f1202084d1499babe185032de0d",
            "5d86c6d7f77e4253943e2b73f6adad93",
            "dd59156f663341bda89cddbeccc388e6",
            "9b765a7d634a46a5a0b4fae443430916",
            "2bb6f46e74d34436ae53fef7437833c2",
            "d73a35fae2d648feb5267d8001e59afa"
          ]
        },
        "id": "rl9C8hs0n2L7",
        "outputId": "3ab35163-04ea-4156-e7d7-d61c7d7a3f13"
      },
      "source": [
        "#모델 형식에 맡게 변환\r\n",
        "sentences = []\r\n",
        "for i in train_data:\r\n",
        "  sentences.append(i[0])\r\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\r\n",
        "\r\n",
        "#버트 토크나이저 실행\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89cdddd951c4643b1fa7befc548dae0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d195042ad2fc4680ae8fdfe28624ad2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0385859d00694bcbaa480affd323667e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ggdLMkdojFs"
      },
      "source": [
        "#데이터 텍스트 길이에 맞춰 최대길이 설정\r\n",
        "maxlen = 0\r\n",
        "for i in sentences:\r\n",
        "  if maxlen < len(i):\r\n",
        "    maxlen = len(i)\r\n",
        "##문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "MAX_LEN = maxlen + 1\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "attention_masks = []\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv03SNGyrpjm"
      },
      "source": [
        "#라벨 함수 정의\n",
        "def labeltoint(str):\n",
        "    return {'non-neutral': 0,\n",
        "             'neutral': 1, \n",
        "             'joy': 2,\n",
        "             'sadness': 3,\n",
        "             'fear': 4,\n",
        "             'anger': 5,\n",
        "             'surprise': 6,\n",
        "             'disgust': 7}[str]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0QuLdBvorkF"
      },
      "source": [
        "#라벨 추출 및 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "labels = []\r\n",
        "for i in train_data:\r\n",
        "  labels.append(labeltoint(i[1]))\r\n",
        "\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\r\n",
        "                                                                                    labels, \r\n",
        "                                                                                    random_state=2020, \r\n",
        "                                                                                    test_size=0.1)\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \r\n",
        "                                                       input_ids,\r\n",
        "                                                       random_state=2018, \r\n",
        "                                                       test_size=0.1)\r\n",
        "\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = SequentialSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGew135JrwNi"
      },
      "source": [
        "#테스트데이터 모델 형식에 맞게 변환\n",
        "sentences = []\n",
        "for i in test_data:\n",
        "  sentences.append(i[0])\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRZdtO7woyJL"
      },
      "source": [
        "#데스트데이터 버트 토크나이저 실행\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "#maxlen설정 및 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "maxlen = 0\r\n",
        "for i in sentences:\r\n",
        "  if maxlen < len(i):\r\n",
        "    maxlen = len(i)\r\n",
        "\r\n",
        "MAX_LEN = maxlen + 1\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "attention_masks = []\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "labels = []\r\n",
        "for i in test_data:\r\n",
        "  labels.append(labeltoint(i[1]))\r\n",
        "\r\n",
        "test_inputs = torch.tensor(input_ids)\r\n",
        "test_labels = torch.tensor(labels)\r\n",
        "test_masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpR-_NhLjkee"
      },
      "source": [
        "**모델생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlW5wwl0pTtk",
        "outputId": "fcde326e-7e6e-494d-b5b8-a545da488b2c"
      },
      "source": [
        "#디바이스 설정\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name == '/device:GPU:0':\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "else:\r\n",
        "    raise SystemError('GPU device not found')\r\n",
        "\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZdsrPUlw3Zy",
        "outputId": "dd953501-5fb5-40c6-ff8b-495b9a68c074"
      },
      "source": [
        "#모델 구현\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels=8,  # The number of output labels--2 for binary classification.\n",
        "    output_attentions=False,  # Whether the model returns attentions weights.\n",
        "    output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onqXad0uw-BE",
        "outputId": "ccd36f25-c103-4ce3-8cdf-1aee5ee7956d"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-E0l86mqfj4"
      },
      "source": [
        "#하이퍼 파리미터 설정\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, # 학습률\r\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
        "                )\r\n",
        "epochs = 30\r\n",
        "total_steps = len(train_dataloader) * epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCq900F8qifk"
      },
      "source": [
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkMiixeuqphs"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MgvcVbRqveU"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9HTbGE_jyJq"
      },
      "source": [
        "**모델 학습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXriitdDq0iE",
        "outputId": "5919abfd-6dd8-4154-a12a-35ac78d04599"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\r\n",
        "seed_val = 42\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # 시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 로스 초기화\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    # 훈련모드로 변경\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        # 경과 정보 표시\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        # Forward 수행                \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        # 총 로스 계산\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Backward 수행으로 그래디언트 계산\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # 그래디언트 클리핑\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러로 학습률 감소\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "        # 그래디언트 초기화\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    #시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 변수 초기화\r\n",
        "    eval_loss, eval_accuracy = 0, 0\r\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "        \r\n",
        "        # 그래디언트 계산 안함\r\n",
        "        with torch.no_grad():     \r\n",
        "            # Forward 수행\r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        logits = outputs[0]\r\n",
        "\r\n",
        "        # CPU로 데이터 이동\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "        \r\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Training epcoh took: 0:02:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.45\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.71\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.42\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.43\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.43\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.45\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.45\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.45\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 15 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 16 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 17 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 18 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 19 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.45\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 20 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.46\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 21 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 22 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 23 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.46\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 24 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 25 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 26 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 27 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 28 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 29 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:02:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 30 / 30 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.44\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT5v4d3swI33",
        "outputId": "df061d5d-f8e5-41b1-96b9-d6331968fe50"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApYIUcepj4th"
      },
      "source": [
        "**예측 데이터 로드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DeSrFtrgwU4p",
        "outputId": "ae5f7544-fa9f-424d-a445-2e90383ba5cb"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d3cb142-1961-479c-955c-942e80348308\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d3cb142-1961-479c-955c-942e80348308\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"chujungyeon\",\"key\":\"51de4f95a4f6282a429db57d3d56d7d6\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3xRYhoawpE1"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!mv kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dDXpMFYwyIt",
        "outputId": "731aeec6-7a63-4632-b614-5c3875c7f777"
      },
      "source": [
        "!kaggle competitions download -c english-sa-competition-dfe610"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "en_data.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaLFYehow3bE"
      },
      "source": [
        "with open('en_data.csv', 'r', encoding='mac_roman', newline='') as csvfile:\r\n",
        "  en = pd.read_csv(csvfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjE9ZdFQj9bx"
      },
      "source": [
        "예측 데이터 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUkq9wjpxjRO"
      },
      "source": [
        "# 입력 데이터 변환\r\n",
        "def convert_input_data(sentences):\r\n",
        "\r\n",
        "    # koelectra의 토크나이저로 문장을 토큰으로 분리\r\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "    # 입력 토큰의 최대 시퀀스 길이\r\n",
        "    MAX_LEN = 128\r\n",
        "\r\n",
        "    # 토큰을 숫자 인덱스로 변환\r\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "    \r\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "    # 어텐션 마스크 초기화\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "    for seq in input_ids:\r\n",
        "        seq_mask = [float(i>0) for i in seq]\r\n",
        "        attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "    # 데이터를 파이토치의 텐서로 변환\r\n",
        "    inputs = torch.tensor(input_ids)\r\n",
        "    masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return inputs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84bSzedtxnqV"
      },
      "source": [
        "def test_sentences(sentences):\r\n",
        "    model.eval()\r\n",
        "    inputs, masks = convert_input_data(sentences)\r\n",
        "\r\n",
        "    b_input_ids = inputs.to(device)\r\n",
        "    b_input_mask = masks.to(device)\r\n",
        "            \r\n",
        "    with torch.no_grad():     \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    logits = outputs[0]\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9i15X8hxMK9"
      },
      "source": [
        "\r\n",
        "def inttolabel(idx):\r\n",
        "    return {0:'non-neutral',\r\n",
        "             1:'neutral', \r\n",
        "             2:'joy',\r\n",
        "             3:'sadness',\r\n",
        "             4:'fear',\r\n",
        "             5:'anger',\r\n",
        "             6:'surprise',\r\n",
        "             7:'disgust'}[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9OP42HkAm6"
      },
      "source": [
        "**예측 실행**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hiY4DteyKc-"
      },
      "source": [
        "#데이터 예측 실행 및 데이터 프레임생성\r\n",
        "en_data = [['Id', 'Expected']]\r\n",
        "\r\n",
        "for idx in range(len(en['utterance'])):\r\n",
        "  sen = en['utterance'][idx]\r\n",
        "  logit = test_sentences([sen])\r\n",
        "  \r\n",
        "  en_data.append([idx, inttolabel(np.argmax(logit))])\r\n",
        "\r\n",
        "dataframe = pd.DataFrame(en_data)\r\n",
        "dataframe.to_csv(\"en_test.csv\", header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoUPSfhzy093",
        "outputId": "c21fdd4c-06c7-49e5-93b0-7b1f344a2967"
      },
      "source": [
        "!kaggle competitions submit -c english-sa-competition-dfe610 -f en_test.csv -m \"chujungyeon\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "100% 19.9k/19.9k [00:05<00:00, 3.93kB/s]\n",
            "Successfully submitted to English SA Competition - DFE610"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}